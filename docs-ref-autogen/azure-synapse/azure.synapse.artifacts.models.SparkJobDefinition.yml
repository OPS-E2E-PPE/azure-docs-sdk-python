### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SparkJobDefinition
name: SparkJobDefinition
fullName: azure.synapse.artifacts.models.SparkJobDefinition
module: azure.synapse.artifacts.models
inheritances:
- msrest.serialization.Model
summary: 'Spark job definition.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkJobDefinition(*, target_big_data_pool: azure.synapse.artifacts.models._models_py3.BigDataPoolReference,
    job_properties: azure.synapse.artifacts.models._models_py3.SparkJobProperties,
    additional_properties: typing.Union[typing.Dict[str, object], NoneType] = None,
    description: typing.Union[str, NoneType] = None, required_spark_version: typing.Union[str,
    NoneType] = None, language: typing.Union[str, NoneType] = None, **kwargs)'
  parameters:
  - name: additional_properties
    description: 'Unmatched properties from the message are deserialized to this

      collection.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: description
    description: The description of the Spark job definition.
    isRequired: true
    types:
    - <xref:str>
  - name: target_big_data_pool
    description: Required. Big data pool reference.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.BigDataPoolReference>
  - name: required_spark_version
    description: The required Spark version of the application.
    isRequired: true
    types:
    - <xref:str>
  - name: language
    description: The language of the Spark application.
    isRequired: true
    types:
    - <xref:str>
  - name: job_properties
    description: Required. The properties of the Spark job.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.SparkJobProperties>
